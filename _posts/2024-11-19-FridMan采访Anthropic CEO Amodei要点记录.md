---
title: FridMan采访Anthropic CEO Amodei要点记录
date: 2024-11-19 13:08:42 +0800
categories: 技术
tags:
  - AI
layout: single
toc: "true"
toc_label: 目录
toc_icon: list
toc_sticky: "true"
sidebar:
  nav: docs
comments: "true"
---
1. Scaling Law的限制可能会来源于数据缺乏和数据质量，但是可以用AI生成的数据或者强化学习的数据（本质也是一种生成数据）来弥补；另一个限制可能是需要新的优化方法和技术。但Amodei目前并没有看到Scaling Law遇到瓶颈的证据，仍需要建设更大的数据中心，可能是目前规模的100倍。
3. Sonnet 3.5 不仅仅受益于预训练，也来自于后训练过程的改进，以及精细化的评估方法。
4. 后训练不仅仅有RHLF，还有其它的方法，后训练正在变得越来越复杂
5. 模型的命名和参数定义很难，因为每个模型都有很多的属性，甚至是个性，就和人一样。和传统软件的定义和命名不一样。
6. 模型的行为很难控制和引导，比如它的过分道歉行为。需要做了各种情况的均衡。每次做一些调整，都需要做大量的回归测试和评估。(我猜测，这就是Anthropic一直要做模型可解释的其中一个原因。)
7. 有时候觉得模型变笨，是由于A/B测试或者是系统提示词修改