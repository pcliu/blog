---
title: FridMan采访Anthropic CEO Amodei要点记录
date: 2024-11-19 13:08:42 +0800
categories: 技术
tags:
  - AI
layout: single
toc: "true"
toc_label: 目录
toc_icon: list
toc_sticky: "true"
sidebar:
  nav: docs
comments: "true"
---
1. Scaling Law的限制可能会来源于数据缺乏和数据质量，但是可以用AI生成的数据或者强化学习的数据（本质也是一种生成数据）来弥补；另一个限制可能是需要新的优化方法和技术。但Amodei目前并没有看到Scaling Law遇到瓶颈的证据，仍需要建设更大的数据中心，可能是目前规模的100倍。
3. Sonnet 3.5 不仅仅受益于预训练，也来自于后训练过程的改进，以及精细化的评估方法。
4. 后训练不仅仅有RHLF，还有其它的方法，后训练正在变得越来越复杂
5. 模型的命名和参数定义很难，因为每个模型都有很多的属性，甚至是个性，就和人一样。和传统软件的定义和命名不一样。
6. 模型的行为很难控制和引导，比如它的过分道歉行为。需要做了各种情况的均衡。每次做一些调整，都需要做大量的回归测试和评估。(我猜测，这就是Anthropic一直要做模型可解释的其中一个原因。)
7. 有时候觉得模型变笨，是由于A/B测试或者是系统提示词修改
8. AI安全等级（AI Safety Levels，简称ASL）是一套用于评估和分类AI系统安全性的框架，旨在确定AI系统在自主性和潜在滥用风险方面的能力水平。以下是ASL的几个分类的总结，目前处于ASL2，正在部署ASL3级别的安全措施，今年年底或明年能会触发ASL3级别

| 级别        | 描述                                                                                                  |
| --------- | --------------------------------------------------------------------------------------------------- |
| **ASL-1** | 这一级别的系统被认为没有任何自主性或滥用的风险。这些系统通常是非常特定和有限的任务型AI，例如国际象棋或围棋的AI，它们被设计为只能执行单一任务，没有能力进行自我复制或执行超出其设计目的的复杂任务。 |
| **ASL-2** | 当前的AI系统大多处于这一级别，它们被认为没有足够的智能来进行自主复制或执行复杂任务，也没有能力提供超出现有搜索引擎能力的有关危险物品（如化学、生物、放射性、核武器）的制造信息。           |
| **ASL-3** | 在这一级别，AI系统的能力足以增强非国家行为者的能力。这些系统可能需要特别的安全措施，以防止模型被非国家行为者盗用和滥用。                                       |
| **ASL-4** | 这一级别的AI系统可能增强已经具备一定知识的国家行为者的能力，或者成为主要的风险源。这些系统可能需要更严格的安全和监控措施，以确保它们不会用于恶意目的。                        |
| **ASL-5** | 这是最高级别的AI系统，它们在执行任何任务上的能力可能超过人类，包括自主性和其他高风险活动。在这一级别，AI系统的安全和监管将成为全球性的挑战。                            |
9. AI安全等级（AI Safety Levels，简称ASL）是一套用于评估和分类AI系统安全性的框架，旨在确定AI系统在自主性和潜在滥用风险方面的能力水平。以下是ASL的几个分类的总结：
10. 