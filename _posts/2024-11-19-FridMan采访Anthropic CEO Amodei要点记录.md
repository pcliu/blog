---
title: FridMan采访Anthropic CEO Amodei要点记录
date: 2024-11-19 13:08:42 +0800
categories: 技术
tags:
  - AI
layout: single
toc: "true"
toc_label: 目录
toc_icon: list
toc_sticky: "true"
sidebar:
  nav: docs
comments: "true"
---
1. Scaling Law的限制可能会来源于数据缺乏和数据质量，但是可以用AI生成的数据或者强化学习的数据（本质也是一种生成数据）来弥补；另一个限制可能是需要新的优化方法和技术。但Amodei目前并没有看到Scaling Law遇到瓶颈的证据，仍需要建设更大的数据中心，可能是目前规模的100倍。
3. Sonnet 3.5 不仅仅受益于预训练，也来自于后训练过程的改进，以及精细化的评估方法。
4. 后训练不仅仅有RHLF，还有其它的方法，后训练正在变得越来越复杂
5. 模型的命名和参数定义很难，因为每个模型都有很多的属性，甚至是个性，就和人一样。和传统软件的定义和命名不一样。
6. 模型的行为很难控制和引导，比如它的过分道歉行为。需要做了各种情况的均衡。每次做一些调整，都需要做大量的回归测试和评估。(我猜测，这就是Anthropic一直要做模型可解释的其中一个原因。)
7. 有时候觉得模型变笨，是由于A/B测试或者是系统提示词修改
8. AI安全等级（AI Safety Levels，简称ASL）是一套用于评估和分类AI系统安全性的框架，旨在确定AI系统在自主性和潜在滥用风险方面的能力水平。以下是ASL的几个分类的总结，目前处于ASL2，正在部署ASL3级别的安全措施，今年年底或明年能会触发ASL3级别

| 级别    | 描述                                                                                                  |
| ----- | --------------------------------------------------------------------------------------------------- |
| ASL-1 | 这一级别的系统被认为没有任何自主性或滥用的风险。这些系统通常是非常特定和有限的任务型AI，例如国际象棋或围棋的AI，它们被设计为只能执行单一任务，没有能力进行自我复制或执行超出其设计目的的复杂任务。 |
| ASL-2 | 当前的AI系统大多处于这一级别，它们被认为没有足够的智能来进行自主复制或执行复杂任务，也没有能力提供超出现有搜索引擎能力的有关危险物品（如化学、生物、放射性、核武器）的制造信息。           |
| ASL-3 | 在这一级别，AI系统的能力足以增强非国家行为者的能力。这些系统可能需要特别的安全措施，以防止模型被非国家行为者盗用和滥用。                                       |
| ASL-4 | 这一级别的AI系统可能增强已经具备一定知识的国家行为者的能力，或者成为主要的风险源。这些系统可能需要更严格的安全和监控措施，以确保它们不会用于恶意目的。                        |
| ASL-5 | 这是最高级别的AI系统，它们在执行任何任务上的能力可能超过人类，包括自主性和其他高风险活动。在这一级别，AI系统的安全和监管将成为全球性的挑战。                            |
9. AI安全等级（AI Safety Levels，简称ASL）是一套用于评估和分类AI系统安全性的框架，旨在确定AI系统在自主性和潜在滥用风险方面的能力水平。以下是ASL的几个分类的总结：
10. computer user并没有对模型做特殊的训练。
11. 不要强加你自己对模型应该如何学习的想法。
12. 离开openai的原因应该是某种理念不合，证明自己的理念。这个分歧应该是安全方面和可控、可解释方面。
13. 人才密度要比人才数量重要。100全部是高质量人才的团队要比1000个中有200个高质量人才的团队要好。
14. Anthropic招聘了很多理论物理学家
15. 开放心态和新眼光看待事物，对人工智能研究员最重要。
16. 建议人们去玩模型，通过实践来获得经验是很有必要的。顺应做一些新事物、朝新的方向思考的理念，有很多事情尚未被探索。建议研究机制可解释性、长期学习和长期任务、评估方法、多智能体系统。
17. Anthropic的后训练做了要比行业内好，但没有什么黑魔法，只是各个方面可能都做的好一些。
18. 当前行业内预训练成本比例高，但是之后后训练的成本比例高，而且主要由AI来参与，人类的参与难以规模化到满足高质量和高效率的需求